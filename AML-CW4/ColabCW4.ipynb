{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ColabCW4.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "RLjPCF06SNEv"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "3pWXNtxQHEdG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ed2ab9a-f2b6-43e7-fbbf-07e8e1f47eca"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f931079cd90>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "from PIL import Image\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "torch.manual_seed(1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "colab = \"/content/drive/Othercomputers/내 iMac/Meta_Learning/코스웍/2022 고급기계학습주제 (김광인)/과제/CW4/code\""
      ],
      "metadata": {
        "id": "75RZwqULIZsz"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 0.Loading Dataset"
      ],
      "metadata": {
        "id": "FfTc4t8yJDFF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ICVLDataset(Dataset):\n",
        "    def __init__(self, csv_file, img_dir, transform=transforms.Normalize(mean=[1881.42],std=[12.29]), target_transform=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            csv_file (string): csv 파일의 경로\n",
        "            img_dir (string): 모든 이미지가 존재하는 디렉토리 경로\n",
        "            transform (callable, optional): 샘플에 적용될 Optional transform\n",
        "            target_transform (callable, optional): 타겟 샘플에 적용될 Optional transform\n",
        "        \"\"\"\n",
        "        self.img_targets = pd.read_csv(\n",
        "            csv_file,\n",
        "            usecols = [i for i in range(1,64)],\n",
        "            skiprows = [1,2,3]\n",
        "        )\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.img_targets)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        ImagePATH = self.img_dir + \"depth_1_\" + str(idx).zfill(7) + \".png\"\n",
        "        image = torch.FloatTensor(np.array(Image.open(ImagePATH))) #float32\n",
        "        image = image.unsqueeze(0)\n",
        "        # image = Image.open(ImagePATH)\n",
        "        target = torch.FloatTensor(self.img_targets.iloc[idx])\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        if self.target_transform:\n",
        "            target = self.target_transform(target)\n",
        "        return image, target"
      ],
      "metadata": {
        "id": "6uxSprY7HzYB"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = ICVLDataset(csv_file=os.path.join(colab,\"data/Training/Annotation_Training.csv\"), img_dir=os.path.join(colab, \"data/Training/depth/\"))\n",
        "test_dataset = ICVLDataset(csv_file=os.path.join(colab,\"data/Testing/Annotation_Testing.csv\"), img_dir=os.path.join(colab,\"data/Testing/depth/\"))"
      ],
      "metadata": {
        "id": "sWTbyQCGKXXC"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(dataset=train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=32, shuffle=True)"
      ],
      "metadata": {
        "id": "5wFJrUvaKmqY"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for img, target in train_loader:\n",
        "    print(img.shape)\n",
        "    print(target.shape)\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "unuxL_xqNXb5",
        "outputId": "1eb16bdb-06bb-4ce0-cc8c-1bf748f981e7"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 1, 240, 320])\n",
            "torch.Size([32, 63])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mean and Std"
      ],
      "metadata": {
        "id": "RLjPCF06SNEv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mean, std calculation\n",
        "# c=0\n",
        "# means = []\n",
        "# stds = []\n",
        "# for img, target in train_loader:\n",
        "#     print(img.shape)\n",
        "#     print(target.shape)\n",
        "#     means.append(img.mean())\n",
        "#     stds.append(img.std())\n",
        "#     c+=1\n",
        "#     if c == 4:\n",
        "#       break\n",
        "\n",
        "# np.mean(means)\n",
        "# np.std(stds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YAxqHhE5Kqyr",
        "outputId": "0a96e464-02a6-48d7-d7c6-fd9bec7b1d12"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 1, 240, 320])\n",
            "torch.Size([32, 63])\n",
            "torch.Size([32, 1, 240, 320])\n",
            "torch.Size([32, 63])\n",
            "torch.Size([32, 1, 240, 320])\n",
            "torch.Size([32, 63])\n",
            "torch.Size([32, 1, 240, 320])\n",
            "torch.Size([32, 63])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12.292542"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# mean = np.mean(means)\n",
        "# std = np.std(stds)\n",
        "# print(\"mean\", mean)\n",
        "# print(\"std\", std)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HgOKISQ9M69u",
        "outputId": "20b4f740-bf06-4dd6-e74c-568466539bb9"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean 1881.421\n",
            "std 12.292542\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.Model"
      ],
      "metadata": {
        "id": "1i8LQrPNSRs7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "VDKrd_xjSTa9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}